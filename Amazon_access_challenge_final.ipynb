{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From all the experimentation that was done using various models, the most that gave the best performance(high Test AUC score) was **CatBoost**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using Catboost Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function 1 : Predicting the class label**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class_catboost(input):\n",
    "    \"\"\"this function predicts the final o/p class label\"\"\"\n",
    "    train=pd.read_csv('train.csv')\n",
    "    test=input\n",
    "    train_data=train.drop(columns=['ACTION'],axis=1)\n",
    "    test_data=test.drop(columns=['id'],axis=1)\n",
    "    y_true = train['ACTION']\n",
    "    train_data.shape,test_data.shape,y_true.shape\n",
    "    categorical_features = list(range(train_data.shape[1]))\n",
    "    \n",
    "    params = {'loss_function':'Logloss',\n",
    "             'eval_metric':'AUC',\n",
    "              'cat_features':categorical_features,\n",
    "              'verbose':200,\n",
    "              'random_seed':42}\n",
    "\n",
    "    model = CatBoostClassifier(**params)\n",
    "    model.fit(train_data,y_true)\n",
    "    output = model.predict(test_data)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.045713\n",
      "0:\ttotal: 186ms\tremaining: 3m 5s\n",
      "200:\ttotal: 23.5s\tremaining: 1m 33s\n",
      "400:\ttotal: 52s\tremaining: 1m 17s\n",
      "600:\ttotal: 1m 19s\tremaining: 52.9s\n",
      "800:\ttotal: 1m 47s\tremaining: 26.7s\n",
      "999:\ttotal: 2m 15s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data=pd.read_csv('test.csv')\n",
    "predict_class_catboost(input_data[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function 2 : predicting the performance metric**\n",
    "\n",
    "In this problem, we were given two csv files, train.csv and test.csv . While the train.csv file contains the output class label for all data points, the test.csv file doesn't contain the  output class label which means we can't calculate the AUC metric manually . We need to know the class labels for the data to calculate the AUC score manually.\n",
    "\n",
    "So we have only two options.\n",
    "1. Split the train.csv into train and test data , fit the model using training data and calculate the performance metric using test data\n",
    "\n",
    "2. Use all the data in train.csv to train the model, use the data in test.csv and get the class probabilities , store it in a csv file and upload it in the kaggle comptetition to get the AUC score.\n",
    "        \n",
    "I am choosing option 1 here        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_metric_catboost(X_train,X_test,y_train,y_test):\n",
    "    '''this function calculates the performance metric for given train and test data'''\n",
    "    categorical_features = list(range(train_data.shape[1]))\n",
    "    params = {'loss_function':'Logloss',\n",
    "             'eval_metric':'AUC',\n",
    "              'cat_features':categorical_features,\n",
    "              'verbose':200,\n",
    "              'random_seed':42}\n",
    "    model = CatBoostClassifier(**params)\n",
    "    model.fit(X_train,y_train)    \n",
    "    pred = model.predict_proba(X_test)[:,1]\n",
    "    return roc_auc_score(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24576, 9) (8193, 9) (24576,) (8193,)\n",
      "Learning rate set to 0.040428\n",
      "0:\ttotal: 95.8ms\tremaining: 1m 35s\n",
      "200:\ttotal: 17.8s\tremaining: 1m 10s\n",
      "400:\ttotal: 39.4s\tremaining: 58.9s\n",
      "600:\ttotal: 1m 2s\tremaining: 41.3s\n",
      "800:\ttotal: 1m 23s\tremaining: 20.8s\n",
      "999:\ttotal: 1m 46s\tremaining: 0us\n",
      "Performance metric: AUC : 0.8995517936725808\n"
     ]
    }
   ],
   "source": [
    "train=pd.read_csv('train.csv')\n",
    "train_data=train.drop(columns=['ACTION'],axis=1)\n",
    "y_true = train['ACTION']\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data,y_true, test_size=0.25,stratify=y_true)\n",
    "print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)\n",
    "print('Performance metric: AUC :',predict_metric_catboost(X_train,X_test,y_train,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the CatBoost model, doesnt require any feature transformations, the task was much simpler as you need to just fit the model and predict the class label/calculate the AUC score.\n",
    " \n",
    "\n",
    "\n",
    "Therefore I am trying to write the same functionality using **random forest model that also includes frequency encoded features** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using Random Forest + Frequency Encoding  model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict ={}\n",
    "test_dict={}\n",
    "def freq_encoding(train,test,each):\n",
    "    values=train[each].value_counts()/len(train)\n",
    "    v1 =train[each].map(values).fillna(0)\n",
    "    v2 =test[each].map(values).fillna(0)\n",
    "    return v1,v2\n",
    "\n",
    "\n",
    "def preprocessing(train,test):\n",
    "    for each in train.columns:\n",
    "        v1,v2 = freq_encoding(train,test,each)\n",
    "        train_dict[each+'_train']=v1\n",
    "        test_dict[each+'_test']=v2\n",
    "        \n",
    "    return train_dict,test_dict    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function 1 : Predicting the class label**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_output(input):\n",
    "    #get train data and test data\n",
    "    train=pd.read_csv('train.csv')\n",
    "    train_data=train.drop(columns=['ACTION'],axis=1)\n",
    "    test=input\n",
    "    test_data=test.drop(columns=['id'],axis=1)\n",
    "    print('Shape of train and test data:',train_data.shape,test_data.shape)\n",
    "    print('#'*50)\n",
    "    \n",
    "    #performing data preprocessing\n",
    "    train_fc,test_fc = preprocessing(train_data,test_data)\n",
    "    train_fc=pd.DataFrame(train_fc)\n",
    "    test_fc=pd.DataFrame(test_fc)\n",
    "    print('Shape of frequency coded data:',train_fc.shape,test_fc.shape)\n",
    "    print('#'*50)\n",
    "    \n",
    "    #Concatenate data\n",
    "    mod_train = pd.concat((train_data,train_fc),axis=1)\n",
    "    mod_test = pd.concat((test_data,test_fc),axis=1)\n",
    "    print('Concatenated data shape:',mod_train.shape,mod_test.shape)\n",
    "    print('#'*50)\n",
    "    \n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    model=RandomForestClassifier(n_estimators=1000,max_depth=25,max_features=5,\n",
    "                             min_samples_split=2,\n",
    "                             random_state=42,class_weight='balanced',n_jobs=-1)\n",
    "    model.fit(mod_train,y_true)\n",
    "    print('Model fitted using training data')\n",
    "    #predicting the labels\n",
    "    pred = model.predict(mod_test)\n",
    "    return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train and test data: (32769, 9) (10, 9)\n",
      "##################################################\n",
      "Shape of frequency coded data: (32769, 9) (10, 9)\n",
      "##################################################\n",
      "Concatenated data shape: (32769, 18) (10, 18)\n",
      "##################################################\n",
      "Model fitted using training data\n",
      "Predicted class for the provided input is  [1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "test=pd.read_csv('test.csv')\n",
    "print('Predicted class for the provided input is ', pred_output(test[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function 2 : predicting the performance metric**\n",
    "\n",
    "As explained earlier, i am splitting the train data into train and test since the given test data doesn't contain any class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_metric(X_train,X_test,y_train,y_test):\n",
    "    #perform data preprocessing\n",
    "    train_fc,test_fc = preprocessing(X_train,X_test)\n",
    "    train_fc=pd.DataFrame(train_fc)\n",
    "    test_fc=pd.DataFrame(test_fc)\n",
    "    print('Shape of frequency coded data:',train_fc.shape,test_fc.shape)\n",
    "    print('#'*50)   \n",
    "    \n",
    "    \n",
    "    #Concatenate data\n",
    "    mod_train = pd.concat((X_train,train_fc),axis=1)\n",
    "    mod_test = pd.concat((X_test,test_fc),axis=1)\n",
    "    print('Concatenated data shape:',mod_train.shape,mod_test.shape)\n",
    "    print('#'*50)  \n",
    "\n",
    "    \n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    model=RandomForestClassifier(n_estimators=1000,max_depth=25,max_features=5,\n",
    "                             min_samples_split=2,\n",
    "                             random_state=42,class_weight='balanced',n_jobs=-1)\n",
    "    model.fit(mod_train,y_train)\n",
    "    print('Model fitted using training data')\n",
    "    #predicting the labels\n",
    "    pred = model.predict_proba(mod_test)[:,1]\n",
    "    return roc_auc_score(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24576, 9) (8193, 9) (24576,) (8193,)\n",
      "Shape of frequency coded data: (24576, 9) (8193, 9)\n",
      "##################################################\n",
      "Concatenated data shape: (24576, 18) (8193, 18)\n",
      "##################################################\n",
      "Model fitted using training data\n",
      "Performance metric: AUC : 0.8598218927158204\n"
     ]
    }
   ],
   "source": [
    "train=pd.read_csv('train.csv')\n",
    "train_data=train.drop(columns=['ACTION'],axis=1)\n",
    "y_true = train['ACTION']\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data,y_true, test_size=0.25,stratify=y_true)\n",
    "print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)\n",
    "print('Performance metric: AUC :',pred_metric(X_train,X_test,y_train,y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
